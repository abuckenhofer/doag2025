{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "99b8d531",
      "metadata": {
        "id": "99b8d531"
      },
      "source": [
        "# Delta Lake, Apache Iceberg & DuckLake"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0aa2deaa",
      "metadata": {
        "id": "0aa2deaa"
      },
      "source": [
        "## Format-Überblick (kurz)\n",
        "**Delta Lake**\n",
        "- Offenes Format auf Parquet-Basis mit Transaktionslog (`_delta_log`).\n",
        "- Stärken: Spark-Ökosystem, Time‑Travel, MERGE/UPSERT, breites Tooling.\n",
        "- Schwächen: Spark-Abhängigkeit für viele Features; Log-Vacuum beachten.\n",
        "\n",
        "**Apache Iceberg**\n",
        "- Tabellenformat mit **Snapshots**, versteckter Partitionierung und flexibler Schema‑Evolution.\n",
        "- Stärken: Engine‑neutral (Spark, Flink, Trino, DuckDB), performantes Metadata‑Layout.\n",
        "- Schwächen: Katalogverwaltung (REST/Nessie/Glue/etc.) & Setup‑Varianten können komplex sein.\n",
        "\n",
        "**DuckLake**\n",
        "- Neues offenes Lakehouse‑Format (Metadaten in relationaler DB, z. B. SQLite; Daten als Parquet).\n",
        "- Stärken: einfache lokale Kataloge, schnelle Demos, Snapshot‑APIs; Engine‑agnostisch via DuckDB.\n",
        "- Schwächen: junges Ökosystem; weniger Integrationen als Iceberg/Delta (Stand: 2025)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1adb21fd",
      "metadata": {
        "id": "1adb21fd"
      },
      "source": [
        "## Gewählte Datenquelle\n",
        "- NYC Green Taxi (01/2019, Parquet) → `https://d37ci6vzurychx.cloudfront.net/trip-data/green_tripdata_2019-01.parquet`\n",
        "- Für die Demos wird eine **Teilmenge** benutzt (Limit ~5k Zeilen), um Rechenzeit in Colab kurz zu halten."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "79ed7b2f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "79ed7b2f",
        "outputId": "257de45b-82d7-4930-bd1d-7cc0b0444f0b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Datenquelle: https://d37ci6vzurychx.cloudfront.net/trip-data/green_tripdata_2019-01.parquet\n"
          ]
        }
      ],
      "source": [
        "DATA_URL = 'https://d37ci6vzurychx.cloudfront.net/trip-data/green_tripdata_2019-01.parquet'\n",
        "print('Datenquelle:', DATA_URL)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dfe4fe3b",
      "metadata": {
        "id": "dfe4fe3b"
      },
      "source": [
        "## Delta Lake\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install -qq openjdk-11-jdk-headless > /dev/null\n",
        "!pip install -q pyspark==3.5.1 delta-spark==3.2.0"
      ],
      "metadata": {
        "id": "ONRu59LqEqIL"
      },
      "id": "ONRu59LqEqIL",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from delta import configure_spark_with_delta_pip\n",
        "\n",
        "builder = (\n",
        "    SparkSession.builder\n",
        "    .appName(\"DeltaSchemaEvolutionDemo\")\n",
        "    .config(\n",
        "        \"spark.sql.extensions\",\n",
        "        \"io.delta.sql.DeltaSparkSessionExtension\"\n",
        "    )\n",
        "    .config(\n",
        "        \"spark.sql.catalog.spark_catalog\",\n",
        "        \"org.apache.spark.sql.delta.catalog.DeltaCatalog\"\n",
        "    )\n",
        ")\n",
        "\n",
        "spark = configure_spark_with_delta_pip(builder).getOrCreate()\n",
        "\n",
        "print(\"Spark:\", spark.version)\n",
        "print(\"Extensions:\", spark.conf.get(\"spark.sql.extensions\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U7ZvfK2vDpis",
        "outputId": "c095d79d-1648-4dd5-d253-a85159547a09"
      },
      "id": "U7ZvfK2vDpis",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spark: 3.5.1\n",
            "Extensions: io.delta.sql.DeltaSparkSessionExtension\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_path = \"/content/delta/events_demo\"\n",
        "\n",
        "events_v1 = spark.createDataFrame(\n",
        "    [\n",
        "        (1, \"signup\"),\n",
        "        (2, \"purchase\"),\n",
        "        (3, \"signup\"),\n",
        "    ],\n",
        "    [\"user_id\", \"event_type\"]\n",
        ")\n",
        "\n",
        "(\n",
        "    events_v1.write\n",
        "        .format(\"delta\")\n",
        "        .mode(\"overwrite\")\n",
        "        .save(base_path)\n",
        ")\n",
        "\n",
        "df = spark.read.format(\"delta\").load(base_path)\n",
        "df.printSchema()\n",
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fEHjQqS5D2Yx",
        "outputId": "76096035-d409-4d2c-caf3-d54125226c5f"
      },
      "id": "fEHjQqS5D2Yx",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- user_id: long (nullable = true)\n",
            " |-- event_type: string (nullable = true)\n",
            "\n",
            "+-------+----------+\n",
            "|user_id|event_type|\n",
            "+-------+----------+\n",
            "|      2|  purchase|\n",
            "|      3|    signup|\n",
            "|      1|    signup|\n",
            "+-------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Schema ändern\n",
        "events_v2 = spark.createDataFrame(\n",
        "    [\n",
        "        (4, \"signup\",   \"mobile\"),\n",
        "        (5, \"purchase\", \"web\"),\n",
        "    ],\n",
        "    [\"user_id\", \"event_type\", \"device_type\"]\n",
        ")\n",
        "\n",
        "(\n",
        "    events_v2.write\n",
        "        .format(\"delta\")\n",
        "        .mode(\"append\")\n",
        "        .option(\"mergeSchema\", \"true\")  # Schema-Evolution\n",
        "        .save(base_path)\n",
        ")\n",
        "\n",
        "df2 = spark.read.format(\"delta\").load(base_path)\n",
        "df2.printSchema()\n",
        "df2.orderBy(\"user_id\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dcaDsH15ESSn",
        "outputId": "cb812b96-0214-419a-ba69-a0c4ce0a6e67"
      },
      "id": "dcaDsH15ESSn",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- user_id: long (nullable = true)\n",
            " |-- event_type: string (nullable = true)\n",
            " |-- device_type: string (nullable = true)\n",
            "\n",
            "+-------+----------+-----------+\n",
            "|user_id|event_type|device_type|\n",
            "+-------+----------+-----------+\n",
            "|      1|    signup|       NULL|\n",
            "|      2|  purchase|       NULL|\n",
            "|      3|    signup|       NULL|\n",
            "|      4|    signup|     mobile|\n",
            "|      5|  purchase|        web|\n",
            "+-------+----------+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Zugriff mittels SQL\n",
        "base_path = \"/content/delta/events_demo\"  # wie beim Schreiben\n",
        "\n",
        "spark.sql(f\"\"\"\n",
        "  CREATE TABLE IF NOT EXISTS events_demo\n",
        "  USING DELTA\n",
        "  LOCATION '{base_path}'\n",
        "\"\"\")\n",
        "\n",
        "spark.sql(\"SELECT * FROM events_demo ORDER BY user_id\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6bBAKmmKGool",
        "outputId": "3842e387-c8b7-4d5d-afff-fd7d80da104f"
      },
      "id": "6bBAKmmKGool",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+----------+-----------+\n",
            "|user_id|event_type|device_type|\n",
            "+-------+----------+-----------+\n",
            "|      1|    signup|       NULL|\n",
            "|      2|  purchase|       NULL|\n",
            "|      3|    signup|       NULL|\n",
            "|      4|    signup|     mobile|\n",
            "|      5|  purchase|        web|\n",
            "+-------+----------+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Alternativ DDL erweitern\n",
        "spark.sql(\"\"\"\n",
        "  ALTER TABLE events_demo\n",
        "  ADD COLUMNS (event_date DATE)\n",
        "\"\"\")\n",
        "\n",
        "spark.sql(\"DESCRIBE TABLE events_demo\").show(truncate=False)\n",
        "spark.sql(\"SELECT * FROM events_demo ORDER BY user_id\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S63nJpTAEeIG",
        "outputId": "faf0a56b-c4fc-4fca-ea6d-2409fad7c742"
      },
      "id": "S63nJpTAEeIG",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+---------+-------+\n",
            "|col_name   |data_type|comment|\n",
            "+-----------+---------+-------+\n",
            "|user_id    |bigint   |NULL   |\n",
            "|event_type |string   |NULL   |\n",
            "|device_type|string   |NULL   |\n",
            "|event_date |date     |NULL   |\n",
            "+-----------+---------+-------+\n",
            "\n",
            "+-------+----------+-----------+----------+\n",
            "|user_id|event_type|device_type|event_date|\n",
            "+-------+----------+-----------+----------+\n",
            "|      1|    signup|       NULL|      NULL|\n",
            "|      2|  purchase|       NULL|      NULL|\n",
            "|      3|    signup|       NULL|      NULL|\n",
            "|      4|    signup|     mobile|      NULL|\n",
            "|      5|  purchase|        web|      NULL|\n",
            "+-------+----------+-----------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CS3-YBCfHtR_"
      },
      "id": "CS3-YBCfHtR_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9cf7de66",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9cf7de66",
        "outputId": "87b9a0f8-c45c-4e7d-9bf8-d193785c9ac4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.5/20.5 MB\u001b[0m \u001b[31m40.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.6/56.6 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m92.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "# Delta ohne Spark: mit delta-rs (Write/History) + DuckDB (Read/Analytics)\n",
        "# -> nutzt dieselbe Datenquelle wie Iceberg/DuckLake\n",
        "%pip -q install deltalake duckdb==1.4.2 pyarrow pandas"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, pandas as pd, duckdb\n",
        "from deltalake import DeltaTable, write_deltalake\n",
        "\n",
        "DATA_URL = globals().get(\n",
        "    \"DATA_URL\",\n",
        "    \"https://d37ci6vzurychx.cloudfront.net/trip-data/green_tripdata_2019-01.parquet\"\n",
        ")"
      ],
      "metadata": {
        "id": "GSK7KsKTcn1z"
      },
      "id": "GSK7KsKTcn1z",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "816cc2fa",
      "metadata": {
        "id": "816cc2fa"
      },
      "outputs": [],
      "source": [
        "# Quelle laden (pandas/pyarrow), auf ~5k Zeilen begrenzen\n",
        "pdf = pd.read_parquet(DATA_URL, engine=\"pyarrow\", columns=[\n",
        "    \"lpep_pickup_datetime\",\"lpep_dropoff_datetime\",\n",
        "    \"passenger_count\",\"trip_distance\",\"total_amount\"\n",
        "]).head(5000)\n",
        "\n",
        "delta_path = \"/content/delta_trips\"  # lokaler Delta-Tabellenpfad\n",
        "os.makedirs(delta_path, exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(pdf)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7H3UO1o2IU6k",
        "outputId": "275d05d8-bb26-4e4b-b092-f84090fa1849"
      },
      "id": "7H3UO1o2IU6k",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     lpep_pickup_datetime lpep_dropoff_datetime  passenger_count  \\\n",
            "0     2018-12-21 15:17:29   2018-12-21 15:18:57              5.0   \n",
            "1     2019-01-01 00:10:16   2019-01-01 00:16:32              2.0   \n",
            "2     2019-01-01 00:27:11   2019-01-01 00:31:38              2.0   \n",
            "3     2019-01-01 00:46:20   2019-01-01 01:04:54              2.0   \n",
            "4     2019-01-01 00:19:06   2019-01-01 00:39:43              1.0   \n",
            "...                   ...                   ...              ...   \n",
            "4995  2019-01-01 04:40:03   2019-01-01 04:43:51              2.0   \n",
            "4996  2019-01-01 04:00:25   2019-01-01 04:12:11              1.0   \n",
            "4997  2019-01-01 04:26:41   2019-01-01 04:45:38              1.0   \n",
            "4998  2019-01-01 04:36:17   2019-01-01 04:41:04              1.0   \n",
            "4999  2019-01-01 04:08:05   2019-01-01 04:23:24              1.0   \n",
            "\n",
            "      trip_distance  total_amount  \n",
            "0              0.00          4.30  \n",
            "1              0.86          7.30  \n",
            "2              0.66          5.80  \n",
            "3              2.68         19.71  \n",
            "4              4.53         19.30  \n",
            "...             ...           ...  \n",
            "4995           0.63          5.80  \n",
            "4996           6.30         26.06  \n",
            "4997           6.86         28.56  \n",
            "4998           0.82          6.80  \n",
            "4999           8.41         30.36  \n",
            "\n",
            "[5000 rows x 5 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e856e733",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e856e733",
        "outputId": "69db3824-a562-43a7-9d8f-a93ddc4ddb20"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "v0 -> rows: 5000 | version: 0\n"
          ]
        }
      ],
      "source": [
        "# Als Delta schreiben\n",
        "# Erste Version schreiben (delta-rs)\n",
        "write_deltalake(delta_path, pdf, mode=\"overwrite\")  # v0\n",
        "dt = DeltaTable(delta_path)\n",
        "print(\"v0 -> rows:\", len(dt.to_pandas()), \"| version:\", dt.version())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ad194102",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ad194102",
        "outputId": "dbffd2e5-8c89-4e3b-eb87-9625955febc7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "v1 -> rows: 5000 | version: 2\n"
          ]
        }
      ],
      "source": [
        "# Änderung erzeugen (total_amount bei kurze Fahrten erhöhen) und neue Version schreiben\n",
        "pdf2 = pdf.copy()\n",
        "mask = pdf2[\"trip_distance\"] < 0.5\n",
        "\n",
        "# wählt alle Zeilen, mit mask == True, und nur die Spalte total_amount wird erhöht\n",
        "pdf2.loc[mask, \"total_amount\"] = pdf2.loc[mask, \"total_amount\"] + 0.20\n",
        "\n",
        "write_deltalake(delta_path, pdf2, mode=\"overwrite\")  # v1\n",
        "dt = DeltaTable(delta_path)\n",
        "print(\"v1 -> rows:\", len(dt.to_pandas()), \"| version:\", dt.version())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "50d43df0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "50d43df0",
        "outputId": "232b2f73-b857-4800-9e29-cc7be287d00f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "History entries: 3\n",
            "Latest op: WRITE | version: 2\n"
          ]
        }
      ],
      "source": [
        "# History/Time-Travel (delta-rs)\n",
        "hist = dt.history()  # Liste mit Commit-Metadaten\n",
        "print(\"History entries:\", len(hist))\n",
        "print(\"Latest op:\", hist[0].get(\"operation\"), \"| version:\", dt.version())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Delta mit DuckDB lesen\n",
        "con = duckdb.connect()\n",
        "con.execute(\"INSTALL delta; LOAD delta;\")  # autoload funktioniert idR auch ohne diese Zeile\n",
        "res = con.execute(f\"SELECT count(*) AS n FROM delta_scan('file://{delta_path}')\").fetchdf()\n",
        "print(\"DuckDB delta_scan() count:\", int(res['n'][0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oxDTHyokcdeK",
        "outputId": "8ff6a91d-6069-4483-96d1-5bdc80202a3f"
      },
      "id": "oxDTHyokcdeK",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DuckDB delta_scan() count: 5000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Optional: ein Vergleich alter/neuer Werte direkt in pandas (delta-rs)\n",
        "v0 = DeltaTable(delta_path, version=0).to_pandas()\n",
        "v1 = DeltaTable(delta_path).to_pandas()\n",
        "before = v0.loc[v0[\"trip_distance\"] < 0.5, [\"trip_distance\",\"total_amount\"]].head(3)\n",
        "after  = v1.loc[v1[\"trip_distance\"] < 0.5, [\"trip_distance\",\"total_amount\"]].head(3)\n",
        "print(\"Before (v0):\\n\", before)\n",
        "print(\"After  (v1):\\n\",  after)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4iNPw26NchTr",
        "outputId": "08efd98d-7405-4b13-94d5-d30f23752515"
      },
      "id": "4iNPw26NchTr",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before (v0):\n",
            "     trip_distance  total_amount\n",
            "0            0.00          4.30\n",
            "12           0.49         16.80\n",
            "18           0.43          6.36\n",
            "After  (v1):\n",
            "     trip_distance  total_amount\n",
            "0            0.00          4.50\n",
            "12           0.49         17.00\n",
            "18           0.43          6.56\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eb7b4490",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eb7b4490",
        "outputId": "6a111337-804a-4f2e-c97c-37d65c4cac2f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spalten vor Schema-Evolution: ['lpep_pickup_datetime', 'lpep_dropoff_datetime', 'passenger_count', 'trip_distance', 'total_amount', 'amount_per_km']\n",
            "  lpep_pickup_datetime lpep_dropoff_datetime  passenger_count  trip_distance  \\\n",
            "0  2018-12-21 15:17:29   2018-12-21 15:18:57              5.0            0.0   \n",
            "\n",
            "   total_amount  amount_per_km  \n",
            "0           4.5            NaN  \n",
            "Neue Version: 5 | Zeilen (aktueller Snapshot): 40000\n",
            "Spalten nach Schema-Evolution: ['lpep_pickup_datetime', 'lpep_dropoff_datetime', 'passenger_count', 'trip_distance', 'total_amount', 'amount_per_km']\n",
            "  lpep_pickup_datetime lpep_dropoff_datetime  passenger_count  trip_distance  \\\n",
            "0  2019-01-01 00:10:16   2019-01-01 00:16:32              2.0           0.86   \n",
            "\n",
            "   total_amount  amount_per_km  \n",
            "0           7.3       8.488372  \n"
          ]
        }
      ],
      "source": [
        "# Schema Evolution\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import duckdb\n",
        "from deltalake import DeltaTable, write_deltalake\n",
        "\n",
        "# delta_path sollte aus der vorherigen Delta+DuckDB-Zelle kommen\n",
        "delta_path = globals().get(\"delta_path\", \"/content/delta_trips\")\n",
        "\n",
        "# Aktuelle Tabelle lesen (pandas)\n",
        "dt = DeltaTable(delta_path)\n",
        "pdf = dt.to_pandas()\n",
        "\n",
        "# Schema via DuckDB inspizieren\n",
        "con = duckdb.connect()\n",
        "preview = con.execute(f\"SELECT * FROM delta_scan('file://{delta_path}') LIMIT 1\").fetchdf()\n",
        "print(\"Spalten vor Schema-Evolution:\", list(preview.columns))\n",
        "print(preview)\n",
        "\n",
        "# Neue Spalte berechnen (Division durch 0 abfangen)\n",
        "new_col = \"amount_per_km\"\n",
        "if new_col not in pdf.columns:\n",
        "    pdf[new_col] = np.where(\n",
        "        (pdf[\"trip_distance\"].astype(float) > 0),\n",
        "        pdf[\"total_amount\"].astype(float) / pdf[\"trip_distance\"].astype(float),\n",
        "        np.nan\n",
        "    )\n",
        "\n",
        "# Schema-Evolution durchführen:\n",
        "#    WICHTIG: statt overwrite -> append und schema_mode=\"merge\"\n",
        "write_deltalake(\n",
        "    delta_path,\n",
        "    pdf,\n",
        "    mode=\"append\",          # Daten anhängen\n",
        "    schema_mode=\"merge\"     # Schema mit neuer Spalte zusammenführen (Delta-RS)\n",
        ")\n",
        "\n",
        "# Version & Schema prüfen\n",
        "dt2 = DeltaTable(delta_path)\n",
        "print(\"Neue Version:\", dt2.version(), \"| Zeilen (aktueller Snapshot):\", len(dt2.to_pandas()))\n",
        "\n",
        "# Schema via DuckDB inspizieren\n",
        "con = duckdb.connect()\n",
        "preview = con.execute(f\"SELECT * FROM delta_scan('file://{delta_path}') where amount_per_km is not null LIMIT 1\").fetchdf()\n",
        "print(\"Spalten nach Schema-Evolution:\", list(preview.columns))\n",
        "print(preview)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Apache Iceberg Copy on write vs Merge on read"
      ],
      "metadata": {
        "id": "BrC9phAqp6E2"
      },
      "id": "BrC9phAqp6E2"
    },
    {
      "cell_type": "code",
      "source": [
        "#!apt-get install -qq openjdk-11-jdk-headless > /dev/null\n",
        "#!pip install -q pyspark==3.5.1"
      ],
      "metadata": {
        "id": "RZsF0f3-tit_"
      },
      "id": "RZsF0f3-tit_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sitzung neu starten!"
      ],
      "metadata": {
        "id": "gCOJ5ZT3_elA"
      },
      "id": "gCOJ5ZT3_elA"
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_URL = 'https://d37ci6vzurychx.cloudfront.net/trip-data/green_tripdata_2019-01.parquet'\n",
        "print('Datenquelle:', DATA_URL)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OjJxrp3N-s9y",
        "outputId": "eee12f0d-3a26-47f9-f61b-fc62801cad42"
      },
      "id": "OjJxrp3N-s9y",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Datenquelle: https://d37ci6vzurychx.cloudfront.net/trip-data/green_tripdata_2019-01.parquet\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder \\\n",
        "  .appName(\"IcebergLocalDevelopment\") \\\n",
        "  .config('spark.jars.packages', 'org.apache.iceberg:iceberg-spark-runtime-3.5_2.12:1.5.2') \\\n",
        "  .config(\"spark.sql.extensions\", \"org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions\") \\\n",
        "  .config(\"spark.sql.catalog.local\", \"org.apache.iceberg.spark.SparkCatalog\") \\\n",
        "  .config(\"spark.sql.catalog.local.type\", \"hadoop\") \\\n",
        "  .config(\"spark.sql.catalog.local.warehouse\", \"spark-warehouse/iceberg\") \\\n",
        "  .getOrCreate()\n",
        "spark.sql(\"SHOW DATABASES\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Km-dQo9tGgW",
        "outputId": "99ef4a7f-707c-41d0-9897-bfcc95dd17ff"
      },
      "id": "8Km-dQo9tGgW",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+\n",
            "|namespace|\n",
            "+---------+\n",
            "|  default|\n",
            "+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "pdf = pd.read_parquet(\n",
        "    DATA_URL,\n",
        "    engine=\"pyarrow\",\n",
        "    columns=[\n",
        "        \"lpep_pickup_datetime\",\n",
        "        \"lpep_dropoff_datetime\",\n",
        "        \"passenger_count\",\n",
        "        \"trip_distance\",\n",
        "        \"total_amount\",\n",
        "    ],\n",
        ").head(5000)\n",
        "\n",
        "# pandas → Spark-DataFrame\n",
        "trips_df = spark.createDataFrame(pdf)"
      ],
      "metadata": {
        "id": "a4L10OF_yvW4"
      },
      "id": "a4L10OF_yvW4",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark.sql(\"CREATE NAMESPACE IF NOT EXISTS local.schema\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zY8qmJe6z1cK",
        "outputId": "2f712069-2575-4daf-c899-6f85208ef38b"
      },
      "id": "zY8qmJe6z1cK",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(\n",
        "    trips_df.writeTo(\"local.schema.trips_cow\")\n",
        "          .tableProperty(\"format-version\", \"2\")\n",
        "          .tableProperty(\"write.update.mode\", \"copy-on-write\")\n",
        "          .createOrReplace()\n",
        ")"
      ],
      "metadata": {
        "id": "pkqVi4q-uQnb"
      },
      "id": "pkqVi4q-uQnb",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(\n",
        "    trips_df.writeTo(\"local.schema.trips_mor\")\n",
        "          .tableProperty(\"format-version\", \"2\")\n",
        "          .tableProperty(\"write.update.mode\", \"merge-on-read\")\n",
        "          .createOrReplace()\n",
        ")"
      ],
      "metadata": {
        "id": "ySxqLmry3SFW"
      },
      "id": "ySxqLmry3SFW",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark.sql(\"select * from local.schema.trips_mor\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xR_r1coN3n7R",
        "outputId": "6edf6f5f-5659-42e0-b3b2-1ce6839e5011"
      },
      "id": "xR_r1coN3n7R",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+---------------------+---------------+-------------+------------+\n",
            "|lpep_pickup_datetime|lpep_dropoff_datetime|passenger_count|trip_distance|total_amount|\n",
            "+--------------------+---------------------+---------------+-------------+------------+\n",
            "| 2018-12-21 15:17:29|  2018-12-21 15:18:57|            5.0|          0.0|         4.3|\n",
            "| 2019-01-01 00:10:16|  2019-01-01 00:16:32|            2.0|         0.86|         7.3|\n",
            "| 2019-01-01 00:27:11|  2019-01-01 00:31:38|            2.0|         0.66|         5.8|\n",
            "| 2019-01-01 00:46:20|  2019-01-01 01:04:54|            2.0|         2.68|       19.71|\n",
            "| 2019-01-01 00:19:06|  2019-01-01 00:39:43|            1.0|         4.53|        19.3|\n",
            "| 2019-01-01 00:12:35|  2019-01-01 00:19:09|            1.0|         1.05|         7.8|\n",
            "| 2019-01-01 00:47:55|  2019-01-01 01:00:01|            1.0|         3.77|        14.8|\n",
            "| 2019-01-01 00:12:47|  2019-01-01 00:30:50|            1.0|          4.1|        17.3|\n",
            "| 2019-01-01 00:16:23|  2019-01-01 00:39:46|            1.0|         7.75|        26.8|\n",
            "| 2019-01-01 00:58:02|  2019-01-01 01:19:02|            1.0|         3.68|        16.8|\n",
            "| 2019-01-01 00:37:00|  2019-01-01 00:56:42|            1.0|         6.84|       37.06|\n",
            "| 2019-01-01 00:13:48|  2019-01-01 00:21:00|            2.0|         1.15|        9.36|\n",
            "| 2019-01-01 00:19:59|  2019-01-01 00:45:50|            1.0|         0.49|        16.8|\n",
            "| 2019-01-01 00:57:57|  2019-01-01 01:20:10|            1.0|         3.61|        18.3|\n",
            "| 2019-01-01 00:09:02|  2019-01-01 00:17:50|            1.0|          1.2|        14.0|\n",
            "| 2019-01-01 00:22:12|  2019-01-01 00:25:29|            1.0|          0.5|         5.3|\n",
            "| 2019-01-01 00:31:55|  2019-01-01 00:52:59|            1.0|          5.5|       24.95|\n",
            "| 2019-01-01 00:30:20|  2019-01-01 00:54:19|            1.0|         5.01|       25.56|\n",
            "| 2018-12-31 23:58:06|  2019-01-01 00:00:57|            1.0|         0.43|        6.36|\n",
            "| 2019-01-01 00:40:17|  2019-01-01 00:50:23|            1.0|         2.72|       14.16|\n",
            "+--------------------+---------------------+---------------+-------------+------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bei COW-Table wird bei einem UPDATE die betroffene Datei komplett neu geschrieben.\n",
        "Bei MOR-Table wird nichts „überschrieben“, sondern es werden neue Daten + Delete-Datei angelegt und die alten Dateien bleiben erhalten."
      ],
      "metadata": {
        "id": "EKmAoXz-BTD1"
      },
      "id": "EKmAoXz-BTD1"
    },
    {
      "cell_type": "code",
      "source": [
        "#spark.sql(\"SELECT * FROM local.schema.trips_cow\").show()\n",
        "\n",
        "# Welche Dateien gehören zu welchen Snapshots?\n",
        "spark.sql(\"\"\"\n",
        "  SELECT\n",
        "    content,         -- 0 = Data, 1 = Position-Delete, 2 = Equality-Delete\n",
        "    file_format,\n",
        "    file_path,\n",
        "    record_count\n",
        "  FROM local.schema.trips_cow.files\n",
        "  ORDER BY content, file_path\n",
        "\"\"\").show(truncate=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mnhtRnS62jTR",
        "outputId": "46a36690-941c-4aa9-9c83-4ba47b2403b6"
      },
      "id": "mnhtRnS62jTR",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+-----------+----------------------------------------------------------------------------------------------------------+------------+\n",
            "|content|file_format|file_path                                                                                                 |record_count|\n",
            "+-------+-----------+----------------------------------------------------------------------------------------------------------+------------+\n",
            "|0      |PARQUET    |spark-warehouse/iceberg/schema/trips_cow/data/00000-6-331fcf20-6257-4349-aaa2-717ca7bc9ea8-0-00001.parquet|5000        |\n",
            "+-------+-----------+----------------------------------------------------------------------------------------------------------+------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#spark.sql(\"SELECT * FROM local.schema.trips_mor\").show()\n",
        "\n",
        "spark.sql(\"\"\"\n",
        "  SELECT\n",
        "    content,         -- 0 = Data, 1 = Position-Delete, 2 = Equality-Delete\n",
        "    file_format,\n",
        "    file_path,\n",
        "    record_count\n",
        "  FROM local.schema.trips_mor.files\n",
        "  ORDER BY content, file_path\n",
        "\"\"\").show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MSRrlrRy5feg",
        "outputId": "445d0e06-abbc-4eaf-a771-e06f1a9ab4d5"
      },
      "id": "MSRrlrRy5feg",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+-----------+----------------------------------------------------------------------------------------------------------------+------------+\n",
            "|content|file_format|file_path                                                                                                       |record_count|\n",
            "+-------+-----------+----------------------------------------------------------------------------------------------------------------+------------+\n",
            "|0      |PARQUET    |spark-warehouse/iceberg/schema/trips_mor/data/00000-2-a482cd66-84f1-4518-a1a2-ed513134e92e-0-00001.parquet      |2048        |\n",
            "|0      |PARQUET    |spark-warehouse/iceberg/schema/trips_mor/data/00000-8-68c66947-6d3f-48ab-8cc4-ef11f1bd4d45-00001.parquet        |5000        |\n",
            "|0      |PARQUET    |spark-warehouse/iceberg/schema/trips_mor/data/00001-3-a482cd66-84f1-4518-a1a2-ed513134e92e-0-00001.parquet      |2952        |\n",
            "|1      |PARQUET    |spark-warehouse/iceberg/schema/trips_mor/data/00000-8-68c66947-6d3f-48ab-8cc4-ef11f1bd4d45-00001-deletes.parquet|5000        |\n",
            "+-------+-----------+----------------------------------------------------------------------------------------------------------------+------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Die beiden Dateien mit\n",
        "2048 und 2952 Zeilen (zusammen 2048 + 2952 = 5000) sind die ursprünglichen Datenfiles vor dem UPDATE.\n",
        "\n",
        "Das File mit record_count = 5000 und content = 0 ist die neue Daten-Datei mit den geänderten passenger_count-Werten.\n",
        "\n",
        "Das deletes.parquet mit content = 1 und record_count = 5000 ist eine Position-Delete-Datei:\n",
        "\n",
        "sie enthält 5000 Einträge, die auf alle ursprünglichen 5000 Zeilen in den zwei alten Dateien verweisen\n",
        "\n",
        "damit werden diese alten Zeilen logisch gelöscht."
      ],
      "metadata": {
        "id": "hi-gS8oSBnlw"
      },
      "id": "hi-gS8oSBnlw"
    },
    {
      "cell_type": "code",
      "source": [
        "spark.sql(\"UPDATE local.schema.trips_mor SET passenger_count = passenger_count + 1 WHERE total_amount > 240\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BJDdIHx_3ezk",
        "outputId": "8f7acd9f-5867-486c-946b-aff1f6f469f5"
      },
      "id": "BJDdIHx_3ezk",
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spark.sql(\"\"\"\n",
        "  SELECT\n",
        "    content,         -- 0 = Data, 1 = Position-Delete, 2 = Equality-Delete\n",
        "    file_format,\n",
        "    file_path,\n",
        "    record_count\n",
        "  FROM local.schema.trips_mor.files\n",
        "  ORDER BY content, file_path\n",
        "\"\"\").show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eq8bxG8YFo09",
        "outputId": "38d3c939-1d53-40e7-bebd-8b59a0b03fb7"
      },
      "id": "eq8bxG8YFo09",
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+-----------+----------------------------------------------------------------------------------------------------------------+------------+\n",
            "|content|file_format|file_path                                                                                                       |record_count|\n",
            "+-------+-----------+----------------------------------------------------------------------------------------------------------------+------------+\n",
            "|0      |PARQUET    |spark-warehouse/iceberg/schema/trips_mor/data/00000-2-a482cd66-84f1-4518-a1a2-ed513134e92e-0-00001.parquet      |2048        |\n",
            "|0      |PARQUET    |spark-warehouse/iceberg/schema/trips_mor/data/00000-4-f16123ec-edf0-4130-acf4-08bea9e2c625-00001.parquet        |1           |\n",
            "|0      |PARQUET    |spark-warehouse/iceberg/schema/trips_mor/data/00000-8-68c66947-6d3f-48ab-8cc4-ef11f1bd4d45-00001.parquet        |5000        |\n",
            "|0      |PARQUET    |spark-warehouse/iceberg/schema/trips_mor/data/00001-3-a482cd66-84f1-4518-a1a2-ed513134e92e-0-00001.parquet      |2952        |\n",
            "|1      |PARQUET    |spark-warehouse/iceberg/schema/trips_mor/data/00000-4-f16123ec-edf0-4130-acf4-08bea9e2c625-00001-deletes.parquet|1           |\n",
            "|1      |PARQUET    |spark-warehouse/iceberg/schema/trips_mor/data/00000-8-68c66947-6d3f-48ab-8cc4-ef11f1bd4d45-00001-deletes.parquet|5000        |\n",
            "+-------+-----------+----------------------------------------------------------------------------------------------------------------+------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Update 2: nur 1 Zeile\n",
        "\n",
        "Iceberg packt die neue Version dieser einen Zeile in ein Mini-Datenfile\n",
        "\n",
        "und schreibt ein Delete-File mit 1 Delete-Eintrag, der die alte Version dieser Zeile löscht\n"
      ],
      "metadata": {
        "id": "B63heML6G5VP"
      },
      "id": "B63heML6G5VP"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aufräumen:\n",
        "\n",
        "* expire_snapshots → alte Snapshots + deren nicht benötigte Dateien\n",
        "aufräumen\n",
        "* remove_orphan_files → Dateien löschen, die in keinem Snapshot mehr vorkommen\n",
        "* rewrite_data_files → viele kleine Datafiles zu größeren zusammenfassen (Compaction)\n",
        "* (optional) rewrite_position_deletes / rewrite_manifests für Feintuning"
      ],
      "metadata": {
        "id": "wMYmHaM2-e_C"
      },
      "id": "wMYmHaM2-e_C"
    },
    {
      "cell_type": "markdown",
      "id": "990bcbe8",
      "metadata": {
        "id": "990bcbe8"
      },
      "source": [
        "## Apache Iceberg (via DuckDB Iceberg‑Extension)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0dae4a30",
      "metadata": {
        "id": "0dae4a30",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "43c1f0ac-6802-4991-c7a2-df2849ebb6f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting duckdb==1.4.2\n",
            "  Downloading duckdb-1.4.2-cp312-cp312-manylinux_2_26_x86_64.manylinux_2_28_x86_64.whl.metadata (4.3 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: sqlalchemy in /usr/local/lib/python3.12/dist-packages (2.0.44)\n",
            "Requirement already satisfied: pyarrow in /usr/local/lib/python3.12/dist-packages (18.1.0)\n",
            "Collecting pyiceberg[pyarrow,sql]\n",
            "  Downloading pyiceberg-0.10.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "\u001b[33mWARNING: pyiceberg 0.10.0 does not provide the extra 'sql'\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: cachetools<7.0,>=5.5 in /usr/local/lib/python3.12/dist-packages (from pyiceberg[pyarrow,sql]) (5.5.2)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.12/dist-packages (from pyiceberg[pyarrow,sql]) (8.3.0)\n",
            "Requirement already satisfied: fsspec>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from pyiceberg[pyarrow,sql]) (2025.3.0)\n",
            "Collecting mmh3<6.0.0,>=4.0.0 (from pyiceberg[pyarrow,sql])\n",
            "  Downloading mmh3-5.2.0-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (14 kB)\n",
            "Requirement already satisfied: pydantic!=2.4.0,!=2.4.1,<3.0,>=2.0 in /usr/local/lib/python3.12/dist-packages (from pyiceberg[pyarrow,sql]) (2.11.10)\n",
            "Collecting pyiceberg-core<0.7.0,>=0.5.1 (from pyiceberg[pyarrow,sql])\n",
            "  Downloading pyiceberg_core-0.6.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: pyparsing<4.0.0,>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from pyiceberg[pyarrow,sql]) (3.2.5)\n",
            "Collecting pyroaring<2.0.0,>=1.0.0 (from pyiceberg[pyarrow,sql])\n",
            "  Downloading pyroaring-1.0.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.20.0 in /usr/local/lib/python3.12/dist-packages (from pyiceberg[pyarrow,sql]) (2.32.4)\n",
            "Requirement already satisfied: rich<15.0.0,>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from pyiceberg[pyarrow,sql]) (13.9.4)\n",
            "Requirement already satisfied: sortedcontainers==2.4.0 in /usr/local/lib/python3.12/dist-packages (from pyiceberg[pyarrow,sql]) (2.4.0)\n",
            "Collecting strictyaml<2.0.0,>=1.7.0 (from pyiceberg[pyarrow,sql])\n",
            "  Downloading strictyaml-1.7.3-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: tenacity<10.0.0,>=8.2.3 in /usr/local/lib/python3.12/dist-packages (from pyiceberg[pyarrow,sql]) (8.5.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from sqlalchemy) (3.2.4)\n",
            "Requirement already satisfied: typing-extensions>=4.6.0 in /usr/local/lib/python3.12/dist-packages (from sqlalchemy) (4.15.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic!=2.4.0,!=2.4.1,<3.0,>=2.0->pyiceberg[pyarrow,sql]) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic!=2.4.0,!=2.4.1,<3.0,>=2.0->pyiceberg[pyarrow,sql]) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic!=2.4.0,!=2.4.1,<3.0,>=2.0->pyiceberg[pyarrow,sql]) (0.4.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.20.0->pyiceberg[pyarrow,sql]) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.20.0->pyiceberg[pyarrow,sql]) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.20.0->pyiceberg[pyarrow,sql]) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.20.0->pyiceberg[pyarrow,sql]) (2025.10.5)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich<15.0.0,>=10.11.0->pyiceberg[pyarrow,sql]) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich<15.0.0,>=10.11.0->pyiceberg[pyarrow,sql]) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich<15.0.0,>=10.11.0->pyiceberg[pyarrow,sql]) (0.1.2)\n",
            "Downloading duckdb-1.4.2-cp312-cp312-manylinux_2_26_x86_64.manylinux_2_28_x86_64.whl (20.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.5/20.5 MB\u001b[0m \u001b[31m79.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mmh3-5.2.0-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (103 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.3/103.3 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyiceberg_core-0.6.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.6/30.6 MB\u001b[0m \u001b[31m58.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyroaring-1.0.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m68.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading strictyaml-1.7.3-py3-none-any.whl (123 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.9/123.9 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyiceberg-0.10.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (1.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m64.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pyroaring, pyiceberg-core, mmh3, duckdb, strictyaml, pyiceberg\n",
            "  Attempting uninstall: duckdb\n",
            "    Found existing installation: duckdb 1.3.2\n",
            "    Uninstalling duckdb-1.3.2:\n",
            "      Successfully uninstalled duckdb-1.3.2\n",
            "Successfully installed duckdb-1.4.2 mmh3-5.2.0 pyiceberg-0.10.0 pyiceberg-core-0.6.0 pyroaring-1.0.3 strictyaml-1.7.3\n"
          ]
        }
      ],
      "source": [
        "%pip install duckdb==1.4.2 pandas \"pyiceberg[pyarrow,sql]\" sqlalchemy pyarrow"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import duckdb\n",
        "import pandas as pd\n",
        "\n",
        "print(\"DuckDB: \", duckdb.__version__)\n",
        "print(\"Pandas: \", pd.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oYkD90woLdmg",
        "outputId": "91f08b19-80b6-45e2-f973-e81ea90f51da"
      },
      "id": "oYkD90woLdmg",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DuckDB:  1.4.2\n",
            "Pandas:  2.2.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "con = duckdb.connect()\n",
        "con.execute(\"INSTALL httpfs; LOAD httpfs;\")\n",
        "con.execute(\"INSTALL iceberg; LOAD iceberg;\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y6YqZfmIPPnK",
        "outputId": "3ca2dd2c-1e2c-44fd-d45b-042855dfca79"
      },
      "id": "y6YqZfmIPPnK",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_duckdb.DuckDBPyConnection at 0x780d3e73b6f0>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pyarrow as pa\n",
        "from pyiceberg.catalog.sql import SqlCatalog\n",
        "from pyiceberg.exceptions import NamespaceAlreadyExistsError\n",
        "from pyiceberg.schema import Schema\n",
        "from pyiceberg.types import NestedField, TimestampType, IntegerType, DoubleType\n",
        "\n",
        "# Lokalen Iceberg-Katalog (SQLite) + Warehouse\n",
        "warehouse = \"file:///content/warehouse\"                 # Daten + Metadata landen hier\n",
        "catalog   = SqlCatalog(\n",
        "    name=\"local\",\n",
        "    uri=\"sqlite:////content/iceberg_catalog.db\",        # Katalog-DB-Datei\n",
        "    warehouse=warehouse,\n",
        ")\n",
        "\n",
        "# Namespace + Tabellenbezeichner\n",
        "ns = (\"nyc\",)\n",
        "try:\n",
        "    catalog.create_namespace(ns)\n",
        "except NamespaceAlreadyExistsError:\n",
        "    pass\n",
        "\n",
        "table_name = \"green_2019_01\"\n",
        "identifier = (*ns, table_name)    # -> ('nyc','green_2019_01')\n",
        "\n",
        "# (Optional) vorhandene Tabelle löschen, um Schema-Konflikte zu vermeiden\n",
        "if catalog.table_exists(identifier):\n",
        "    catalog.drop_table(identifier)\n",
        "\n",
        "# Iceberg-Schema (numerische Felder optional, um Nulls zu erlauben)\n",
        "schema = Schema(\n",
        "    NestedField(1, \"lpep_pickup_datetime\",  TimestampType(), required=False),\n",
        "    NestedField(2, \"lpep_dropoff_datetime\", TimestampType(), required=False),\n",
        "    NestedField(3, \"passenger_count\",       IntegerType(),   required=False),\n",
        "    NestedField(4, \"trip_distance\",         DoubleType(),    required=False),\n",
        "    NestedField(5, \"total_amount\",          DoubleType(),    required=False),\n",
        ")\n",
        "\n",
        "# Tabelle anlegen\n",
        "tbl = catalog.create_table(identifier=identifier, schema=schema)\n",
        "\n",
        "# Daten aus HTTP-Parquet lesen und passend casten\n",
        "arrow_tbl = con.sql(\"\"\"\n",
        "    SELECT\n",
        "      lpep_pickup_datetime::TIMESTAMP  AS lpep_pickup_datetime,\n",
        "      lpep_dropoff_datetime::TIMESTAMP AS lpep_dropoff_datetime,\n",
        "      CAST(passenger_count AS INTEGER) AS passenger_count,\n",
        "      CAST(trip_distance   AS DOUBLE)  AS trip_distance,\n",
        "      CAST(total_amount    AS DOUBLE)  AS total_amount\n",
        "    FROM read_parquet('https://d37ci6vzurychx.cloudfront.net/trip-data/green_tripdata_2019-01.parquet')\n",
        "\"\"\").arrow().read_all()\n",
        "\n",
        "# Schreiben (erste Snapshot-Version)\n",
        "tbl.overwrite(arrow_tbl)\n",
        "print(\"OK – Iceberg-Tabelle angelegt und befüllt:\", identifier, \"Warehouse:\", warehouse)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SsgIfLUtE-1t",
        "outputId": "7070a121-7633-44c9-8923-5a163cf1cb77"
      },
      "id": "SsgIfLUtE-1t",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/pyiceberg/table/__init__.py:715: UserWarning: Delete operation did not match any records\n",
            "  warnings.warn(\"Delete operation did not match any records\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OK – Iceberg-Tabelle angelegt und befüllt: ('nyc', 'green_2019_01') Warehouse: file:///content/warehouse\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Optional: mit DuckDB prüfen (ohne Katalog, direkt via metadata.json)\n",
        "# Pfad aus file:// URL extrahieren\n",
        "from urllib.parse import urlparse, unquote\n",
        "import os\n",
        "\n",
        "# Pfade aus der file:// URL\n",
        "latest_meta_url = tbl.metadata_location                                   # file:///.../nyc/green_2019_01/metadata/00001-....metadata.json\n",
        "meta_local = unquote(urlparse(latest_meta_url).path)                      # /.../nyc/green_2019_01/metadata/00001-....metadata.json\n",
        "table_root = os.path.dirname(os.path.dirname(meta_local))                 # /.../nyc/green_2019_01\n",
        "print(meta_local)\n",
        "print(table_root)\n",
        "\n",
        "# Version = Dateiname ohne Endung\n",
        "version_name = os.path.splitext(os.path.basename(meta_local))[0]          # \"00001-....metadata\" -> erst Endung \".json\" ab\n",
        "if version_name.endswith(\".metadata\"):                                     # sicherheitshalber zweite Endung entfernen\n",
        "    version_name = version_name[:-len(\".metadata\")]\n",
        "\n",
        "con.sql(f\"\"\"\n",
        "    SELECT *\n",
        "    FROM iceberg_snapshots(\n",
        "        '{meta_local}',\n",
        "        version = '1'\n",
        "     )\n",
        "\"\"\").df()\n",
        "\n",
        "\n",
        "con.sql(f\"\"\"\n",
        "    SELECT COUNT(*) AS n\n",
        "    FROM iceberg_scan('{meta_local}')\n",
        "\"\"\").df()\n",
        "\n",
        "# DuckDB-Scan: Root + Version + Namensformat\n",
        "#    Namensformat zeigt auf \"metadata/<version>.metadata.json\"\n",
        "con.sql(\"SET unsafe_enable_version_guessing = true\")\n",
        "con.sql(f\"\"\"\n",
        "    SELECT COUNT(*) AS n\n",
        "    FROM iceberg_scan('{table_root}',\n",
        "                      allow_moved_paths=true)\n",
        "\"\"\").df()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 115
        },
        "id": "qwd9ytRrMwEM",
        "outputId": "02da909d-75d3-4520-8729-a147078a458b"
      },
      "id": "qwd9ytRrMwEM",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/warehouse/nyc/green_2019_01/metadata/00001-f39875e4-95e7-4b1f-bbe4-1455bb006901.metadata.json\n",
            "/content/warehouse/nyc/green_2019_01\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        n\n",
              "0  672105"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d6272de6-ae47-4407-a2ff-3bff1d017dd7\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>n</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>672105</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d6272de6-ae47-4407-a2ff-3bff1d017dd7')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d6272de6-ae47-4407-a2ff-3bff1d017dd7 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d6272de6-ae47-4407-a2ff-3bff1d017dd7');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"\\\"\\\"\\\")\",\n  \"rows\": 1,\n  \"fields\": [\n    {\n      \"column\": \"n\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 672105,\n        \"max\": 672105,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          672105\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Time Travel\n",
        "import pyarrow as pa\n",
        "import pandas as pd\n",
        "\n",
        "# Aktuellen Stand als Pandas holen (alternativ .to_arrow())\n",
        "pdf = tbl.scan().to_pandas()  # PyIceberg scan -> Pandas\n",
        "\n",
        "# Änderung: +0.20 auf sehr kurze Fahrten\n",
        "pdf2 = pdf.copy()\n",
        "mask = pdf2[\"trip_distance\"].astype(float) < 0.5\n",
        "pdf2.loc[mask, \"total_amount\"] = pdf2.loc[mask, \"total_amount\"].astype(float) + 0.20\n",
        "pdf2[\"passenger_count\"] = (\n",
        "    pd.to_numeric(pdf2[\"passenger_count\"], errors=\"coerce\")  # floats -> numeric, ungültige -> NaN\n",
        "      .round()                                              # falls 1.0, 2.0 etc.\n",
        "      .astype(\"Int32\")                                      # pandas nullable Int32 (maps to Arrow int32)\n",
        ")\n",
        "\n",
        "# (Optional, robust) Timestamps normalisieren\n",
        "pdf2[\"lpep_pickup_datetime\"]  = pd.to_datetime(pdf2[\"lpep_pickup_datetime\"],  errors=\"coerce\")\n",
        "pdf2[\"lpep_dropoff_datetime\"] = pd.to_datetime(pdf2[\"lpep_dropoff_datetime\"], errors=\"coerce\")\n",
        "\n",
        "# Neue Snapshot-Version schreiben (Full-table Overwrite für Demo)\n",
        "tbl.overwrite(pa.Table.from_pandas(pdf2))\n",
        "\n",
        "# Snapshot-Infos\n",
        "cur = tbl.current_snapshot()\n",
        "snapshots = list(tbl.snapshots())  # ältester -> neuester\n",
        "print(\"Rows (current):\", len(pdf2),\n",
        "      \"| current snapshot_id:\", cur.snapshot_id if cur else None,\n",
        "      \"| #snapshots:\", len(snapshots))\n",
        "\n",
        "# History/Time-Travel\n",
        "#    v0/v1 analog zu Delta: wir nehmen die ersten beiden Snapshot-IDs\n",
        "if len(snapshots) >= 2:\n",
        "    snap_v0 = snapshots[-2].snapshot_id  # vorletzter = \"v0\" in deiner Demo\n",
        "    snap_v1 = snapshots[-1].snapshot_id  # letzter   = \"v1\"\n",
        "else:\n",
        "    # Falls nur ein Snapshot existiert (Erstschreibvorgang)\n",
        "    snap_v0 = snapshots[-1].snapshot_id\n",
        "    snap_v1 = snapshots[-1].snapshot_id\n",
        "\n",
        "print(\"History entries:\", len(snapshots),\n",
        "      \"| latest operation:\", snapshots[-1].summary.operation if snapshots else None)\n",
        "\n",
        "# DuckDB: konsistente Zählung über iceberg_scan\n",
        "con.sql(\"SET unsafe_enable_version_guessing = true\") # Ensure this is set for root scans\n",
        "res = con.execute(f\"\"\"\n",
        "    SELECT COUNT(*) AS n\n",
        "    FROM iceberg_scan('{table_root}', allow_moved_paths=true)\n",
        "\"\"\").fetchdf()\n",
        "print(\"DuckDB iceberg_scan() count:\", int(res[\"n\"][0]))\n",
        "\n",
        "# Optionaler Vergleich alter/neuer Werte (Time-Travel via snapshot_id)\n",
        "v0 = tbl.scan(snapshot_id=snap_v0).to_pandas()\n",
        "v1 = tbl.scan(snapshot_id=snap_v1).to_pandas()\n",
        "before = v0.loc[v0[\"trip_distance\"].astype(float) < 0.5, [\"trip_distance\",\"total_amount\"]].head(3)\n",
        "after  = v1.loc[v1[\"trip_distance\"].astype(float) < 0.5, [\"trip_distance\",\"total_amount\"]].head(3)\n",
        "print(\"Before (v0):\\n\", before)\n",
        "print(\"After  (v1):\\n\",  after)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mjAbFXJsfSD_",
        "outputId": "6635f36d-795f-4813-8a80-5859100f7990"
      },
      "id": "mjAbFXJsfSD_",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rows (current): 672105 | current snapshot_id: 6662130445376781400 | #snapshots: 3\n",
            "History entries: 3 | latest operation: Operation.APPEND\n",
            "DuckDB iceberg_scan() count: 672105\n",
            "Before (v0):\n",
            " Empty DataFrame\n",
            "Columns: [trip_distance, total_amount]\n",
            "Index: []\n",
            "After  (v1):\n",
            "     trip_distance  total_amount\n",
            "0            0.00          4.50\n",
            "12           0.49         17.00\n",
            "18           0.43          6.56\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Schema Evolution\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pyarrow as pa\n",
        "from pyiceberg.types import DoubleType\n",
        "\n",
        "# Aktuelle Daten\n",
        "pdf = tbl.scan().to_pandas()\n",
        "\n",
        "# Neue Spalte berechnen\n",
        "new_col = \"amount_per_km\"\n",
        "if new_col not in pdf.columns:\n",
        "    td = pd.to_numeric(pdf[\"trip_distance\"], errors=\"coerce\")\n",
        "    ta = pd.to_numeric(pdf[\"total_amount\"],  errors=\"coerce\")\n",
        "    pdf[new_col] = np.where(td > 0, ta / td, np.nan)\n",
        "\n",
        "# Schema-Evolution in Iceberg (Spalte hinzufügen)\n",
        "with tbl.update_schema() as update:\n",
        "    if new_col not in [f.name for f in tbl.schema().columns]:\n",
        "        update.add_column(new_col, DoubleType(), doc=\"total_amount per km\")\n",
        "\n",
        "# Datentyp-Korrekturen für bestehende Spalten (wichtig!)\n",
        "pdf[\"passenger_count\"] = (\n",
        "    pd.to_numeric(pdf[\"passenger_count\"], errors=\"coerce\")\n",
        "      .round()\n",
        "      .astype(\"Int32\")   # pandas nullable Int32 -> Arrow int32\n",
        ")\n",
        "# (optional, robust – Timestamps normalisieren)\n",
        "pdf[\"lpep_pickup_datetime\"]  = pd.to_datetime(pdf[\"lpep_pickup_datetime\"],  errors=\"coerce\")\n",
        "pdf[\"lpep_dropoff_datetime\"] = pd.to_datetime(pdf[\"lpep_dropoff_datetime\"], errors=\"coerce\")\n",
        "\n",
        "# Anhängen\n",
        "tbl.append(pa.Table.from_pandas(pdf))\n",
        "\n",
        "cur = tbl.current_snapshot()\n",
        "print(\"Neue snapshot_id:\", cur.snapshot_id if cur else None, \"| Zeilen:\", len(pdf))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1VXEChVQfVKR",
        "outputId": "74a4554f-4afa-41bb-c54a-ace13919da95"
      },
      "id": "1VXEChVQfVKR",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Neue snapshot_id: 176762555907235440 | Zeilen: 672105\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "422b18cd",
      "metadata": {
        "id": "422b18cd"
      },
      "source": [
        "## DuckLake"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install jupysql duckdb==1.4.2 duckdb-engine\n",
        "%load_ext sql\n",
        "%sql duckdb://"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 523
        },
        "id": "T4tFjpBVLhlJ",
        "outputId": "d77819d5-12b4-497c-dc43-39bb74b8970b"
      },
      "id": "T4tFjpBVLhlJ",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: jupysql in /usr/local/lib/python3.12/dist-packages (0.11.1)\n",
            "Requirement already satisfied: duckdb==1.4.2 in /usr/local/lib/python3.12/dist-packages (1.4.2)\n",
            "Requirement already satisfied: duckdb-engine in /usr/local/lib/python3.12/dist-packages (0.17.0)\n",
            "Requirement already satisfied: prettytable>=3.12.0 in /usr/local/lib/python3.12/dist-packages (from jupysql) (3.16.0)\n",
            "Requirement already satisfied: sqlalchemy in /usr/local/lib/python3.12/dist-packages (from jupysql) (2.0.44)\n",
            "Requirement already satisfied: sqlparse in /usr/local/lib/python3.12/dist-packages (from jupysql) (0.5.3)\n",
            "Requirement already satisfied: ipython-genutils>=0.1.0 in /usr/local/lib/python3.12/dist-packages (from jupysql) (0.2.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from jupysql) (3.1.6)\n",
            "Requirement already satisfied: sqlglot>=11.3.7 in /usr/local/lib/python3.12/dist-packages (from jupysql) (25.20.2)\n",
            "Requirement already satisfied: jupysql-plugin>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from jupysql) (0.4.5)\n",
            "Requirement already satisfied: ploomber-core>=0.2.7 in /usr/local/lib/python3.12/dist-packages (from jupysql) (0.2.27)\n",
            "Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.12/dist-packages (from duckdb-engine) (25.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from ploomber-core>=0.2.7->jupysql) (6.0.3)\n",
            "Requirement already satisfied: posthog>=3.0 in /usr/local/lib/python3.12/dist-packages (from ploomber-core>=0.2.7->jupysql) (7.0.1)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.12/dist-packages (from prettytable>=3.12.0->jupysql) (0.2.14)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from sqlalchemy->jupysql) (3.2.4)\n",
            "Requirement already satisfied: typing-extensions>=4.6.0 in /usr/local/lib/python3.12/dist-packages (from sqlalchemy->jupysql) (4.15.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->jupysql) (3.0.3)\n",
            "Requirement already satisfied: requests<3.0,>=2.7 in /usr/local/lib/python3.12/dist-packages (from posthog>=3.0->ploomber-core>=0.2.7->jupysql) (2.32.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from posthog>=3.0->ploomber-core>=0.2.7->jupysql) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.2 in /usr/local/lib/python3.12/dist-packages (from posthog>=3.0->ploomber-core>=0.2.7->jupysql) (2.9.0.post0)\n",
            "Requirement already satisfied: backoff>=1.10.0 in /usr/local/lib/python3.12/dist-packages (from posthog>=3.0->ploomber-core>=0.2.7->jupysql) (2.2.1)\n",
            "Requirement already satisfied: distro>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from posthog>=3.0->ploomber-core>=0.2.7->jupysql) (1.9.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0,>=2.7->posthog>=3.0->ploomber-core>=0.2.7->jupysql) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0,>=2.7->posthog>=3.0->ploomber-core>=0.2.7->jupysql) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0,>=2.7->posthog>=3.0->ploomber-core>=0.2.7->jupysql) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0,>=2.7->posthog>=3.0->ploomber-core>=0.2.7->jupysql) (2025.10.5)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Connecting to 'duckdb://'"
            ],
            "text/html": [
              "<span style=\"None\">Connecting to &#x27;duckdb://&#x27;</span>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%sql\n",
        "INSTALL ducklake;\n",
        "LOAD ducklake;\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 57
        },
        "id": "_jUzVH5cLOk9",
        "outputId": "d35921e5-47c5-4753-b18a-9244b74daaeb"
      },
      "id": "_jUzVH5cLOk9",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Running query in 'duckdb://'"
            ],
            "text/html": [
              "<span style=\"None\">Running query in &#x27;duckdb://&#x27;</span>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "+---------+\n",
              "| Success |\n",
              "+---------+\n",
              "+---------+"
            ],
            "text/html": [
              "<table>\n",
              "    <thead>\n",
              "        <tr>\n",
              "            <th>Success</th>\n",
              "        </tr>\n",
              "    </thead>\n",
              "    <tbody>\n",
              "    </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%sql\n",
        "ATTACH 'ducklake:metadata.ducklake' AS my_ducklake;\n",
        "USE my_ducklake;"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 57
        },
        "id": "TvGODJahNZD0",
        "outputId": "d8a3d457-68e7-40ff-9516-6f613362cda2"
      },
      "id": "TvGODJahNZD0",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Running query in 'duckdb://'"
            ],
            "text/html": [
              "<span style=\"None\">Running query in &#x27;duckdb://&#x27;</span>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "+---------+\n",
              "| Success |\n",
              "+---------+\n",
              "+---------+"
            ],
            "text/html": [
              "<table>\n",
              "    <thead>\n",
              "        <tr>\n",
              "            <th>Success</th>\n",
              "        </tr>\n",
              "    </thead>\n",
              "    <tbody>\n",
              "    </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%sql\n",
        "FROM ducklake_snapshots('my_ducklake');"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 78
        },
        "id": "_TAwDyZyOf70",
        "outputId": "dbd39b0c-eaa7-4efc-b410-517cfbbc9e8a"
      },
      "id": "_TAwDyZyOf70",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Running query in 'duckdb://'"
            ],
            "text/html": [
              "<span style=\"None\">Running query in &#x27;duckdb://&#x27;</span>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "+-------------+----------------------------------+----------------+-------------------------------+--------+----------------+-------------------+\n",
              "| snapshot_id |          snapshot_time           | schema_version |            changes            | author | commit_message | commit_extra_info |\n",
              "+-------------+----------------------------------+----------------+-------------------------------+--------+----------------+-------------------+\n",
              "|      0      | 2025-11-17 18:11:10.626261+00:00 |       0        | {'schemas_created': ['main']} |  None  |      None      |        None       |\n",
              "+-------------+----------------------------------+----------------+-------------------------------+--------+----------------+-------------------+"
            ],
            "text/html": [
              "<table>\n",
              "    <thead>\n",
              "        <tr>\n",
              "            <th>snapshot_id</th>\n",
              "            <th>snapshot_time</th>\n",
              "            <th>schema_version</th>\n",
              "            <th>changes</th>\n",
              "            <th>author</th>\n",
              "            <th>commit_message</th>\n",
              "            <th>commit_extra_info</th>\n",
              "        </tr>\n",
              "    </thead>\n",
              "    <tbody>\n",
              "        <tr>\n",
              "            <td>0</td>\n",
              "            <td>2025-11-17 18:11:10.626261+00:00</td>\n",
              "            <td>0</td>\n",
              "            <td>{'schemas_created': ['main']}</td>\n",
              "            <td>None</td>\n",
              "            <td>None</td>\n",
              "            <td>None</td>\n",
              "        </tr>\n",
              "    </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%sql\n",
        "CREATE SCHEMA IF NOT EXISTS sales;\n",
        "USE sales;"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 57
        },
        "id": "NCOdeF_ZP6gT",
        "outputId": "62dfa909-160b-4fe1-8bcd-eb2a10558ca7"
      },
      "id": "NCOdeF_ZP6gT",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Running query in 'duckdb://'"
            ],
            "text/html": [
              "<span style=\"None\">Running query in &#x27;duckdb://&#x27;</span>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "+---------+\n",
              "| Success |\n",
              "+---------+\n",
              "+---------+"
            ],
            "text/html": [
              "<table>\n",
              "    <thead>\n",
              "        <tr>\n",
              "            <th>Success</th>\n",
              "        </tr>\n",
              "    </thead>\n",
              "    <tbody>\n",
              "    </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%sql\n",
        "CREATE TABLE IF NOT EXISTS customer (\n",
        "    customer_id INTEGER,  # PRIMARY KEY nicht implementiert\n",
        "    last_name VARCHAR(100) NOT NULL\n",
        ");\n",
        "COMMIT;"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 57
        },
        "id": "TvRQAoj3QH9K",
        "outputId": "1ad67735-f450-474f-f58d-aba6f723812f"
      },
      "id": "TvRQAoj3QH9K",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Running query in 'duckdb://'"
            ],
            "text/html": [
              "<span style=\"None\">Running query in &#x27;duckdb://&#x27;</span>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "+---------+\n",
              "| Success |\n",
              "+---------+\n",
              "+---------+"
            ],
            "text/html": [
              "<table>\n",
              "    <thead>\n",
              "        <tr>\n",
              "            <th>Success</th>\n",
              "        </tr>\n",
              "    </thead>\n",
              "    <tbody>\n",
              "    </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%sql\n",
        "INSERT INTO customer (customer_id, last_name) VALUES\n",
        "(1, 'Maier'),\n",
        "(2, 'Schmitt'),\n",
        "(3, 'Albrecht');\n",
        "COMMIT;"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 57
        },
        "id": "m6Xwi2f4Qk2m",
        "outputId": "70bfde20-72f2-4ca9-b063-c01b9baf7bec"
      },
      "id": "m6Xwi2f4Qk2m",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Running query in 'duckdb://'"
            ],
            "text/html": [
              "<span style=\"None\">Running query in &#x27;duckdb://&#x27;</span>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "+---------+\n",
              "| Success |\n",
              "+---------+\n",
              "+---------+"
            ],
            "text/html": [
              "<table>\n",
              "    <thead>\n",
              "        <tr>\n",
              "            <th>Success</th>\n",
              "        </tr>\n",
              "    </thead>\n",
              "    <tbody>\n",
              "    </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%sql SELECT * FROM customer;"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120
        },
        "id": "dPoOfsClRJEI",
        "outputId": "9e511f22-eb0c-44fe-dd99-03a3701af4a7"
      },
      "id": "dPoOfsClRJEI",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Running query in 'duckdb://'"
            ],
            "text/html": [
              "<span style=\"None\">Running query in &#x27;duckdb://&#x27;</span>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "+-------------+-----------+\n",
              "| customer_id | last_name |\n",
              "+-------------+-----------+\n",
              "|      1      |   Maier   |\n",
              "|      2      |  Schmitt  |\n",
              "|      3      |  Albrecht |\n",
              "+-------------+-----------+"
            ],
            "text/html": [
              "<table>\n",
              "    <thead>\n",
              "        <tr>\n",
              "            <th>customer_id</th>\n",
              "            <th>last_name</th>\n",
              "        </tr>\n",
              "    </thead>\n",
              "    <tbody>\n",
              "        <tr>\n",
              "            <td>1</td>\n",
              "            <td>Maier</td>\n",
              "        </tr>\n",
              "        <tr>\n",
              "            <td>2</td>\n",
              "            <td>Schmitt</td>\n",
              "        </tr>\n",
              "        <tr>\n",
              "            <td>3</td>\n",
              "            <td>Albrecht</td>\n",
              "        </tr>\n",
              "    </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%sql\n",
        "FROM ducklake_snapshots('my_ducklake');"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "TF8uJriJRUKh",
        "outputId": "63a77c59-3589-44c6-ec52-ed36db38f7df"
      },
      "id": "TF8uJriJRUKh",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Running query in 'duckdb://'"
            ],
            "text/html": [
              "<span style=\"None\">Running query in &#x27;duckdb://&#x27;</span>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "+-------------+----------------------------------+----------------+----------------------------------------+--------+----------------+-------------------+\n",
              "| snapshot_id |          snapshot_time           | schema_version |                changes                 | author | commit_message | commit_extra_info |\n",
              "+-------------+----------------------------------+----------------+----------------------------------------+--------+----------------+-------------------+\n",
              "|      0      | 2025-11-17 18:11:10.626261+00:00 |       0        |     {'schemas_created': ['main']}      |  None  |      None      |        None       |\n",
              "|      1      | 2025-11-17 18:11:14.464743+00:00 |       1        |     {'schemas_created': ['sales']}     |  None  |      None      |        None       |\n",
              "|      2      | 2025-11-17 18:11:24.485910+00:00 |       2        | {'tables_created': ['sales.customer']} |  None  |      None      |        None       |\n",
              "|      3      | 2025-11-17 18:11:31.687585+00:00 |       2        |    {'tables_inserted_into': ['2']}     |  None  |      None      |        None       |\n",
              "+-------------+----------------------------------+----------------+----------------------------------------+--------+----------------+-------------------+"
            ],
            "text/html": [
              "<table>\n",
              "    <thead>\n",
              "        <tr>\n",
              "            <th>snapshot_id</th>\n",
              "            <th>snapshot_time</th>\n",
              "            <th>schema_version</th>\n",
              "            <th>changes</th>\n",
              "            <th>author</th>\n",
              "            <th>commit_message</th>\n",
              "            <th>commit_extra_info</th>\n",
              "        </tr>\n",
              "    </thead>\n",
              "    <tbody>\n",
              "        <tr>\n",
              "            <td>0</td>\n",
              "            <td>2025-11-17 18:11:10.626261+00:00</td>\n",
              "            <td>0</td>\n",
              "            <td>{'schemas_created': ['main']}</td>\n",
              "            <td>None</td>\n",
              "            <td>None</td>\n",
              "            <td>None</td>\n",
              "        </tr>\n",
              "        <tr>\n",
              "            <td>1</td>\n",
              "            <td>2025-11-17 18:11:14.464743+00:00</td>\n",
              "            <td>1</td>\n",
              "            <td>{'schemas_created': ['sales']}</td>\n",
              "            <td>None</td>\n",
              "            <td>None</td>\n",
              "            <td>None</td>\n",
              "        </tr>\n",
              "        <tr>\n",
              "            <td>2</td>\n",
              "            <td>2025-11-17 18:11:24.485910+00:00</td>\n",
              "            <td>2</td>\n",
              "            <td>{'tables_created': ['sales.customer']}</td>\n",
              "            <td>None</td>\n",
              "            <td>None</td>\n",
              "            <td>None</td>\n",
              "        </tr>\n",
              "        <tr>\n",
              "            <td>3</td>\n",
              "            <td>2025-11-17 18:11:31.687585+00:00</td>\n",
              "            <td>2</td>\n",
              "            <td>{'tables_inserted_into': ['2']}</td>\n",
              "            <td>None</td>\n",
              "            <td>None</td>\n",
              "            <td>None</td>\n",
              "        </tr>\n",
              "    </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%sql\n",
        "INSERT INTO customer (customer_id, last_name) VALUES\n",
        "(4, 'Berger');\n",
        "COMMIT;"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 57
        },
        "id": "PpahqK5uRskU",
        "outputId": "59b32197-6589-4813-8fa5-1a1f83465209"
      },
      "id": "PpahqK5uRskU",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Running query in 'duckdb://'"
            ],
            "text/html": [
              "<span style=\"None\">Running query in &#x27;duckdb://&#x27;</span>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "+---------+\n",
              "| Success |\n",
              "+---------+\n",
              "+---------+"
            ],
            "text/html": [
              "<table>\n",
              "    <thead>\n",
              "        <tr>\n",
              "            <th>Success</th>\n",
              "        </tr>\n",
              "    </thead>\n",
              "    <tbody>\n",
              "    </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%sql\n",
        "DELETE FROM customer WHERE customer_id = 2;\n",
        "COMMIT;"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 57
        },
        "id": "4nUtWKIIR69g",
        "outputId": "9a1ad39b-6743-4d61-fc88-f4c6876cb4f0"
      },
      "id": "4nUtWKIIR69g",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Running query in 'duckdb://'"
            ],
            "text/html": [
              "<span style=\"None\">Running query in &#x27;duckdb://&#x27;</span>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "+---------+\n",
              "| Success |\n",
              "+---------+\n",
              "+---------+"
            ],
            "text/html": [
              "<table>\n",
              "    <thead>\n",
              "        <tr>\n",
              "            <th>Success</th>\n",
              "        </tr>\n",
              "    </thead>\n",
              "    <tbody>\n",
              "    </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%sql\n",
        "FROM ducklake_snapshots('my_ducklake');"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 183
        },
        "id": "PDwB6Ze1R1vT",
        "outputId": "bf1e9094-e87b-455a-fd61-de397fe21561"
      },
      "id": "PDwB6Ze1R1vT",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Running query in 'duckdb://'"
            ],
            "text/html": [
              "<span style=\"None\">Running query in &#x27;duckdb://&#x27;</span>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "+-------------+----------------------------------+----------------+----------------------------------------+--------+----------------+-------------------+\n",
              "| snapshot_id |          snapshot_time           | schema_version |                changes                 | author | commit_message | commit_extra_info |\n",
              "+-------------+----------------------------------+----------------+----------------------------------------+--------+----------------+-------------------+\n",
              "|      0      | 2025-11-17 18:11:10.626261+00:00 |       0        |     {'schemas_created': ['main']}      |  None  |      None      |        None       |\n",
              "|      1      | 2025-11-17 18:11:14.464743+00:00 |       1        |     {'schemas_created': ['sales']}     |  None  |      None      |        None       |\n",
              "|      2      | 2025-11-17 18:11:24.485910+00:00 |       2        | {'tables_created': ['sales.customer']} |  None  |      None      |        None       |\n",
              "|      3      | 2025-11-17 18:11:31.687585+00:00 |       2        |    {'tables_inserted_into': ['2']}     |  None  |      None      |        None       |\n",
              "|      4      | 2025-11-17 18:11:38.734073+00:00 |       2        |    {'tables_inserted_into': ['2']}     |  None  |      None      |        None       |\n",
              "|      5      | 2025-11-17 18:11:54.859229+00:00 |       2        |     {'tables_deleted_from': ['2']}     |  None  |      None      |        None       |\n",
              "+-------------+----------------------------------+----------------+----------------------------------------+--------+----------------+-------------------+"
            ],
            "text/html": [
              "<table>\n",
              "    <thead>\n",
              "        <tr>\n",
              "            <th>snapshot_id</th>\n",
              "            <th>snapshot_time</th>\n",
              "            <th>schema_version</th>\n",
              "            <th>changes</th>\n",
              "            <th>author</th>\n",
              "            <th>commit_message</th>\n",
              "            <th>commit_extra_info</th>\n",
              "        </tr>\n",
              "    </thead>\n",
              "    <tbody>\n",
              "        <tr>\n",
              "            <td>0</td>\n",
              "            <td>2025-11-17 18:11:10.626261+00:00</td>\n",
              "            <td>0</td>\n",
              "            <td>{'schemas_created': ['main']}</td>\n",
              "            <td>None</td>\n",
              "            <td>None</td>\n",
              "            <td>None</td>\n",
              "        </tr>\n",
              "        <tr>\n",
              "            <td>1</td>\n",
              "            <td>2025-11-17 18:11:14.464743+00:00</td>\n",
              "            <td>1</td>\n",
              "            <td>{'schemas_created': ['sales']}</td>\n",
              "            <td>None</td>\n",
              "            <td>None</td>\n",
              "            <td>None</td>\n",
              "        </tr>\n",
              "        <tr>\n",
              "            <td>2</td>\n",
              "            <td>2025-11-17 18:11:24.485910+00:00</td>\n",
              "            <td>2</td>\n",
              "            <td>{'tables_created': ['sales.customer']}</td>\n",
              "            <td>None</td>\n",
              "            <td>None</td>\n",
              "            <td>None</td>\n",
              "        </tr>\n",
              "        <tr>\n",
              "            <td>3</td>\n",
              "            <td>2025-11-17 18:11:31.687585+00:00</td>\n",
              "            <td>2</td>\n",
              "            <td>{'tables_inserted_into': ['2']}</td>\n",
              "            <td>None</td>\n",
              "            <td>None</td>\n",
              "            <td>None</td>\n",
              "        </tr>\n",
              "        <tr>\n",
              "            <td>4</td>\n",
              "            <td>2025-11-17 18:11:38.734073+00:00</td>\n",
              "            <td>2</td>\n",
              "            <td>{'tables_inserted_into': ['2']}</td>\n",
              "            <td>None</td>\n",
              "            <td>None</td>\n",
              "            <td>None</td>\n",
              "        </tr>\n",
              "        <tr>\n",
              "            <td>5</td>\n",
              "            <td>2025-11-17 18:11:54.859229+00:00</td>\n",
              "            <td>2</td>\n",
              "            <td>{'tables_deleted_from': ['2']}</td>\n",
              "            <td>None</td>\n",
              "            <td>None</td>\n",
              "            <td>None</td>\n",
              "        </tr>\n",
              "    </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import duckdb\n",
        "\n",
        "delete_file = duckdb.sql(f\"\"\"\n",
        "    SELECT file FROM glob('/content/metadata.ducklake.files/sales/customer/*delete.parquet') LIMIT 1;\n",
        "    \"\"\").fetchone()[0]\n",
        "\n",
        "# Was enthält delete file?\n",
        "duckdb.sql(f\"\"\"\n",
        "    SELECT * FROM read_parquet('{delete_file}');\n",
        "    \"\"\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bkuW7VaTTyhF",
        "outputId": "6d0d7952-5f22-4b28-ea98-37bfd1754514"
      },
      "id": "bkuW7VaTTyhF",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "┌──────────────────────────────────────────────────────────────────────────────────────────────┬───────┐\n",
              "│                                          file_path                                           │  pos  │\n",
              "│                                           varchar                                            │ int64 │\n",
              "├──────────────────────────────────────────────────────────────────────────────────────────────┼───────┤\n",
              "│ metadata.ducklake.files/sales/customer/ducklake-019a9303-cf02-7c77-9cf3-afa3f1ff8ae9.parquet │     1 │\n",
              "└──────────────────────────────────────────────────────────────────────────────────────────────┴───────┘"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Time Travel"
      ],
      "metadata": {
        "id": "qeONIMt4VAhT"
      },
      "id": "qeONIMt4VAhT"
    },
    {
      "cell_type": "code",
      "source": [
        "%%sql\n",
        "SELECT MAX(snapshot_id) FROM ducklake_snapshots('my_ducklake');"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 78
        },
        "id": "KWLIqC1FU4-B",
        "outputId": "d664de8c-6ffd-44d6-c748-f5150e2be05b"
      },
      "id": "KWLIqC1FU4-B",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Running query in 'duckdb://'"
            ],
            "text/html": [
              "<span style=\"None\">Running query in &#x27;duckdb://&#x27;</span>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "+------------------+\n",
              "| max(snapshot_id) |\n",
              "+------------------+\n",
              "|        5         |\n",
              "+------------------+"
            ],
            "text/html": [
              "<table>\n",
              "    <thead>\n",
              "        <tr>\n",
              "            <th>max(snapshot_id)</th>\n",
              "        </tr>\n",
              "    </thead>\n",
              "    <tbody>\n",
              "        <tr>\n",
              "            <td>5</td>\n",
              "        </tr>\n",
              "    </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%sql\n",
        "-- vor dem löschen\n",
        "SELECT * FROM customer AT (VERSION => 4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "ZnnFTGvsU_U5",
        "outputId": "d392ccd2-58a4-4bf7-81ad-b8978770946d"
      },
      "id": "ZnnFTGvsU_U5",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Running query in 'duckdb://'"
            ],
            "text/html": [
              "<span style=\"None\">Running query in &#x27;duckdb://&#x27;</span>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "+-------------+-----------+\n",
              "| customer_id | last_name |\n",
              "+-------------+-----------+\n",
              "|      1      |   Maier   |\n",
              "|      2      |  Schmitt  |\n",
              "|      3      |  Albrecht |\n",
              "|      4      |   Berger  |\n",
              "+-------------+-----------+"
            ],
            "text/html": [
              "<table>\n",
              "    <thead>\n",
              "        <tr>\n",
              "            <th>customer_id</th>\n",
              "            <th>last_name</th>\n",
              "        </tr>\n",
              "    </thead>\n",
              "    <tbody>\n",
              "        <tr>\n",
              "            <td>1</td>\n",
              "            <td>Maier</td>\n",
              "        </tr>\n",
              "        <tr>\n",
              "            <td>2</td>\n",
              "            <td>Schmitt</td>\n",
              "        </tr>\n",
              "        <tr>\n",
              "            <td>3</td>\n",
              "            <td>Albrecht</td>\n",
              "        </tr>\n",
              "        <tr>\n",
              "            <td>4</td>\n",
              "            <td>Berger</td>\n",
              "        </tr>\n",
              "    </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a51d9f1e",
      "metadata": {
        "id": "a51d9f1e"
      },
      "source": [
        "## Zusammenfassung: Formate im Vergleich\n",
        "Die folgende Tabelle fasst **Features**, **Vorteile/Nachteile** und **Empfehlungen** zusammen."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6346f573",
      "metadata": {
        "id": "6346f573"
      },
      "source": [
        "| Format | Zentrale Features | Vorteile | Nachteile | Empfehlung |\n",
        "|---|---|---|---|---|\n",
        "| Delta Lake | ACID‑Transaktionen, Time‑Travel, MERGE/UPSERT, Schema‑Evolution | Reifes Spark‑Ökosystem, breite Community | Häufig Spark‑zentrisch, Log‑Pflege (VACUUM) nötig | Wenn du ohnehin Spark einsetzt und schnelle Upserts/MERGEs brauchst |\n",
        "| Apache Iceberg | Snapshot‑basierte Metadaten, verborgene Partitionierung, Schema‑Evolution | Engine‑agnostisch (Spark/Trino/Flink/DuckDB), skalierbare Metadaten | Katalog/Deployment kann komplex sein | Für heterogene Engines & großes Scale-out, wenn Abfrage‑Engine frei wählbar bleiben soll |\n",
        "| DuckLake | Metadaten in SQL‑DB (z. B. SQLite), Daten als Parquet, Snapshots/Changes | Sehr einfacher lokaler Katalog, schnelle Demos/POCs | Jüngeres Ökosystem, weniger Integrationen | Für einfache, portable Setups, lokale Analytics & Lehr-/Demo‑Szenarien |"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2b9cfeef",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2b9cfeef",
        "outputId": "578d4265-aa3d-4ce4-ee41-398ffc54fd73"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "duckdb (py)            1.4.2\n",
            "duckdb extensions      n/a\n",
            "deltalake (delta-rs)   1.2.1\n",
            "delta-spark (Spark)    not installed\n",
            "pyspark                3.5.1\n",
            "pyiceberg              0.10.0\n",
            "pyarrow                18.1.0\n",
            "pandas                 2.2.2\n"
          ]
        }
      ],
      "source": [
        "# Versionsübersicht\n",
        "\n",
        "from importlib.metadata import version, PackageNotFoundError\n",
        "\n",
        "def v(pkg):\n",
        "    try:\n",
        "        return version(pkg)\n",
        "    except PackageNotFoundError:\n",
        "        return None\n",
        "\n",
        "rows = []\n",
        "\n",
        "# DuckDB (Python-Package)\n",
        "import duckdb\n",
        "rows.append((\"duckdb (py)\", duckdb.__version__))\n",
        "\n",
        "# DuckDB-Extensions (falls abrufbar)\n",
        "try:\n",
        "    con_chk = duckdb.connect()\n",
        "    con_chk.execute(\"INSTALL pragma;\")  # no-op, aber falls nicht vorhanden ignorieren\n",
        "    exts = con_chk.execute(\"SELECT name, loaded, installed FROM duckdb_extensions() ORDER BY name\").fetchall()\n",
        "    rows.append((\"duckdb extensions\", \", \".join([f\"{n}{'[*]' if l else ''}\" for n,l,_ in exts]) or \"none\"))\n",
        "except Exception:\n",
        "    rows.append((\"duckdb extensions\", \"n/a\"))\n",
        "\n",
        "# Delta-RS (Python-Package: 'deltalake')\n",
        "dl_rs = v(\"deltalake\")\n",
        "rows.append((\"deltalake (delta-rs)\", dl_rs or \"not installed\"))\n",
        "\n",
        "# Delta-Spark (Python-Package: 'delta-spark' / Modul: 'delta')\n",
        "dl_spark = v(\"delta-spark\") or v(\"delta_core\") or v(\"delta\")\n",
        "rows.append((\"delta-spark (Spark)\", dl_spark or \"not installed\"))\n",
        "\n",
        "# PySpark\n",
        "ps = v(\"pyspark\")\n",
        "rows.append((\"pyspark\", ps or \"not installed\"))\n",
        "\n",
        "# PyIceberg\n",
        "pi = v(\"pyiceberg\")\n",
        "rows.append((\"pyiceberg\", pi or \"not installed\"))\n",
        "\n",
        "# PyArrow & Pandas\n",
        "pa = v(\"pyarrow\")\n",
        "pd = v(\"pandas\")\n",
        "rows.append((\"pyarrow\", pa or \"not installed\"))\n",
        "rows.append((\"pandas\", pd or \"not installed\"))\n",
        "\n",
        "# Ausgabe hübsch formatiert\n",
        "w1 = max(len(k) for k,_ in rows) + 2\n",
        "for k,val in rows:\n",
        "    print(f\"{k:<{w1}} {val}\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}